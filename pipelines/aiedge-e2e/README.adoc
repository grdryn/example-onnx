= aiedge-e2e Tekton Pipeline

:link-odh-aiedge-e2e: https://github.com/opendatahub-io/ai-edge/tree/3d655f307b4a4648db7b7df56be74a43220d4fdb/pipelines/tekton/aiedge-e2e[opendatahub-io/ai-edge]

:link-examples: link:../examples/[examples directory]
:link-examples-readme: link:../examples/README.adoc[README]
:link-example-triton-yaml: link:../examples/spleen-seg-triton.pipelinerun.yaml[spleen-seg-triton.pipelinerun.yaml]
:link-example-openvino-yaml: link:../examples/spleen-seg-openvino-s3.pipelinerun.yaml[spleen-seg-openvino-s3.pipelinerun.yaml]

This pipeline is a copy of the one from {link-odh-aiedge-e2e}, with
minor fixes that have not yet been merged upstream.

To apply this to a cluster, run the following:

[source,console]
----
$ oc apply -k .
----

Example PipelineRun files for this can be found in the {link-examples}
(see the {link-examples-readme} in that directory for pre-requisites
for those examples):

* {link-example-triton-yaml} shows an example that consumes the model
  from this Git repository directly, and builds it into an image to be
  run with the Triton model server. The Containerfile for this example
  also is also sourced from this repository.

* {link-example-openvino-yaml} shows an example that consumes the
  model from an S3/Minio bucket, and builds it into an image to be run
  with the OpenVINO model server. The Containerfile for this example
  is sourced from the opendatahub-io/ai-edge repository.
